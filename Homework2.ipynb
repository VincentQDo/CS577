{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2: N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Out: Thursday, February 20\n",
    "## Due Date: Thursday, March 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This programming assignment is more open-ended than the previous ones. It is centered on the N-gram language models and tasks you to:\n",
    "\n",
    "* download and process a large text dataset in python using the <code>csv</code> library\n",
    "* perform sentence and word tokenization\n",
    "* calculate N-gram counts and probabilities\n",
    "* compare the characteristics of the N-grams across different models\n",
    "* generate random sentences using the models\n",
    "\n",
    "<u>You may work in teams of two or three (2-tuples or 3-tuples?) for this assignment.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Download two large text datasets from Kaggle.</u>\n",
    "\n",
    "The <a href=\"http://kaggle.com\">Kaggle competition hosting site</a> offers a number of free datasets that contain interesting text fields. For this assignment, we will use the \"Wine Reviews\" and \"All the News\" datasets. They can be accessed by selecting the \"Datasets\" header and then searching for these specific datasets. Then, choose \"Data\" from the sub-header, preview some of the csv data and notice how at least one of the columns in the dataset will contain sufficient text. I chose to direct you to these two datasets because the textual content seemed interesting and would have different language characteristics, and both were large csv files that could generate significant n-gram counts, but not be too large of a file.\n",
    "\n",
    "<em>(You can use other datasets if you wish. Others that looked interesting on Kaggle include the \"Yelp Dataset\" (but its over 3GB !!!), \"SMS Spam Collection Dataset\", \"Russian Troll Tweets\", and \"A Million News Headlines\".)</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Process the downloaded <code>csv</code> files in python.</u>\n",
    "\n",
    "There's a nice csv library already included in python for accessing values in that are stored in a comma separated values (csv) format. Read the <a href=\"https://docs.python.org/3/library/csv.html\">csv library documentation</a>.\n",
    "What is the delimiter in your csv files? Open each of the two .csv files that you downloaded using this library and be able to read in the data. Note that we really only care about the text column in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON CODE HERE\n",
    "with open(r'winemag-data_first150k.csv', 'r', encoding='utf-8') as wines, open(r'vocab.txt', 'w', encoding='utf-8') as vocab:\n",
    "    result = csv.reader(wines, delimiter=',')\n",
    "    for i in result:\n",
    "        vocab.write(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'vocab.txt', 'r', encoding='utf-8') as vocab:\n",
    "    content = vocab.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = nltk.word_tokenize(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Perform sentence segmentation and word tokenization.</u>\n",
    "\n",
    "Utilize the nltk module to perform sentence segmentation and word tokenization. But at this point, there are a few decisions that need to be made:\n",
    "\n",
    "* How we should handle the .csv rows in the previous step? If we ignore row makers, and \"lump everything together\", how will that effect our language model?\n",
    "* Do we want to remove punctuation? What is the effect of keeping punctuation in the model?\n",
    "* Do we want to add sentence boundary markers, such as <samp>&lt;S&gt;</samp> and <samp>&lt;/S&gt;</samp>?</li>\n",
    "* Should two the words <samp>The</samp> and <samp>the</samp> be treated as the same? What are the effects of doing, or not doing, this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the sentences and tokens out to files for faster load time.\n",
    "with open(r'tokens.pickle', 'rb') as pickleOut:\n",
    "    tokens = pickle.load(pickleOut)\n",
    "with open(r'sents.pickle', 'rb') as pickleOut:\n",
    "    sents = pickle.load(pickleOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Calculate N-gram counts and compute probabilities.</u>\n",
    "\n",
    "Use a python dictionary (or any suitable data structure) to first compute unigram counts. Then try bigram counts. Finally, trigram counts.\n",
    "\n",
    "How much memory are you using? How fast, or slow, is the code -- how long is this step taking? If it is taking too long, try only using a fraction of your corpus: instead of loading the entire .csv file, try only reading the first 1000 rows of data.\n",
    "\n",
    "Using those counts, compute the probabilities for the unigrams, bigrams, and trigrams, and store those in a new python dictionary (or some other data structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load this cell only on start up\n",
    "with open(r'ctnsUnigram.pickle', 'rb') as unigram:\n",
    "    pickle.load(unigramsCnts ,unigram)\n",
    "with open(r'ctnsBigram.pickle', 'rb') as bigram:\n",
    "    pickle.load(bigramCnts ,bigram)\n",
    "with open(r'ctnsTrigram.pickle', 'rb') as trigram:\n",
    "    pickle.load(trigramCnts ,trigram)\n",
    "    with open(r'probUnigram.pickle', 'rb') as unigram:\n",
    "    pickle.load(unigramProb ,unigram)\n",
    "with open(r'probBigram.pickle', 'rb') as bigram:\n",
    "    pickle.load(bigramProb ,bigram)\n",
    "with open(r'probTrigram.pickle', 'rb') as trigram:\n",
    "    pickle.load(trigramProb ,trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON CODE HERE\n",
    "unigramsOfText = tokens\n",
    "bigramsOfText = list(nltk.bigrams(tokens))\n",
    "trigramsOfText = list(nltk.trigrams(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'unigrams.pickle', 'wb') as unigram:\n",
    "    pickle.dump(unigramsOfText ,unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-dc7a13493e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'bigrams.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbigram\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigramsOfText\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbigram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(r'bigrams.pickle', 'wb') as bigram:\n",
    "    pickle.dump(bigramsOfText ,bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'trigrams.pickle', 'wb') as trigram:\n",
    "    pickle.dump(trigramsOfText ,trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalUnigrams = len(unigramsOfText)\n",
    "totalBigrams = len(bigramsOfText)\n",
    "totalTrigrams = len(trigramsOfText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramsCnts = nltk.FreqDist(unigramsOfText)\n",
    "bigramCnts = nltk.FreqDist(bigramsOfText)\n",
    "trigramCnts = nltk.FreqDist(trigramsOfText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'ctnsUnigram.pickle', 'wb') as unigram:\n",
    "    pickle.dump(unigramsCnts ,unigram)\n",
    "with open(r'ctnsBigram.pickle', 'wb') as bigram:\n",
    "    pickle.dump(bigramCnts ,bigram)\n",
    "with open(r'ctnsTrigram.pickle', 'wb') as trigram:\n",
    "    pickle.dump(trigramCnts ,trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramProb = {x : unigramsCnts[x]/totalTokens for x in unigramsCnts}\n",
    "bigramProb = {x : bigramCnts[x]/totalTokens for x in bigramCnts}\n",
    "trigramProb = {x : trigramCnts[x]/totalTokens for x in trigramCnts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'probUnigram.pickle', 'wb') as unigram:\n",
    "    pickle.dump(unigramProb ,unigram)\n",
    "with open(r'probBigram.pickle', 'wb') as bigram:\n",
    "    pickle.dump(bigramProb ,bigram)\n",
    "with open(r'probTrigram.pickle', 'wb') as trigram:\n",
    "    pickle.dump(trigramProb ,trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Compare the statistics of the corpora.</u>\n",
    "                        \n",
    "Use the results of those calculations that you just made the poor computer painstakingly compute. What are the differences in the most common unigrams between the two language models? Are there interesting differences between the bigram models or trigram models?\n",
    "\n",
    "Be able to sort the n-grams to output the top k with the highest count or probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Generate random sentences from the N-grams models for both datasets.</u>\n",
    "                        \n",
    "We briefly talked about this idea in class. It's also introduced at a high-level in J&M 4.3. How can a random number in the range [0,1] probabilistically generate a word using your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a technical report (in this Jupyter Notebook, with good Markdown formatting) that documents your findings, \"lessons learned\", any areas of where you ran into difficult, and also any other interesting details. Include in your report the following details:\n",
    "\n",
    "1. Names of the datasets used.\n",
    "1. Does your model use all of the data in the .csv file or only a subset of it (i.e. first 1,000 rows)?\n",
    "1. What is the vocabulary and size of each dataset?\n",
    "1. How did you handle the merging of separate rows in a .csv file? How did you handle sentence segmentation with sentence boundary markers? Also report on any other decisions made in step #3.\n",
    "1. How long did it take your program to build these models? Do you have any statistics on memory/RAM usage?\n",
    "1. Output the top 15 unigrams, bigrams, trigrams for each model. Are there any interesting differences?\n",
    "1. Output 3 different randomly generated sentences for each unigram, bigram, trigram model. How did you know where the randomly generated sentence ended?\n",
    "\n",
    "Also submit this python notebook `.ipynb` to D2L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON CODE AND REPORT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
